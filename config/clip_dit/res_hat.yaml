machine: ks

model:
  num_hat: 4
  stages: [0, 9, 18, 27]

  dit_head:
    in_channels: 1024
    out_channels: 1024
    condition_channels: 3584
    num_tokens: 4

    hidden_size: 3584
    num_heads: 28
    depth: 4

# dit_head:
#   in_channels: 1024
#   out_channels: 1024
#   condition_channels: 1024
#   num_tokens: 4

#   hidden_size: 1024
#   num_heads: 16
#   depth: 16
train:
  root: null
  resume_path: null
  global_step: 0

  exp_name: &exp_name clip_1024
  wandb_proj: *exp_name
  output_dir: 0828_reshat
  logging_dir: logs
  mixed_precision: bf16
  gradient_accumulation_steps: 1
  report_to: null

  lr: 1e-4
  num_iter: 500000
  save_every: 10000

data:
  wds_path: [/data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Long-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Short-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-JourneyDB]
  num_train_examples: 35000000
  img_size: 448
  buffer_size: 50
  batch_size: 8
  num_workers: 8
  cfg_drop_rate: 0.1
  num_img_token: 256
  max_seq_length: 512