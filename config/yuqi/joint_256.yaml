machine: ks

model:
  dit:
    dim: 1024
    n_layers: 16
    n_heads: 16
    n_kv_heads: 16
    latent_embedding_size: 1536

  diffhead:
    hidden_size: 1536
    depth: 2
    x_dim: 8
    z_dim: 1536

  tune_backbone: true

feature_down_projector:
  clip_feature_dim: 4096
  feature_dim_output: 8
  ckpt: "/data/phd/jinjiachun/experiment/mmdit/0817_sd3_256/mmdit-mmdit-95000"

train:
  root: null
  resume_path: "/data/phd/jinjiachun/experiment/clip_1024/0829_ar_256x8/internvl-clip_1024-95000"
  global_step: 0

  exp_name: &exp_name clip_1024
  wandb_proj: *exp_name
  output_dir: 0829_joint_256x8
  logging_dir: logs
  mixed_precision: bf16
  gradient_accumulation_steps: 1
  report_to: null

  lr: 1e-4
  num_iter: 500000
  save_every: 10000

data:
  wds_path: [/data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Long-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Short-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-JourneyDB]
  num_train_examples: 35000000
  img_size: 448
  buffer_size: 50
  batch_size: 16
  num_workers: 8
  cfg_drop_rate: 0.1
  num_img_token: 256
  max_seq_length: 512