machine: ks
# --------------------------------------------------
model:
  internvl_path: /data/phd/jinjiachun/ckpt/OpenGVLab/InternVL3-2B
  clip_feature_dim: 4096
  diffhead:
    # hidden_size: 3584
    hidden_size: &z_dim 1536
    depth: 2
    x_dim: 16
    z_dim: *z_dim
  mmdit:
    context_dim: 16
    sd3_5_path: /data/phd/jinjiachun/ckpt/stabilityai/stable-diffusion-3.5-medium
    load_pretrained: true
  use_query: true
  query:
    num_queries: 256
    query_dim: 1536
  use_vf: true
  # distmat_margin: 0.25
  # cos_margin: 0.5
  distmat_margin: 0.1
  cos_margin: 0.1
  hp_ar: 10
  hp_dit: 1
  hp_vf: 1
# --------------------------------------------------
train:
  root: null
  resume_path: /data/phd/jinjiachun/experiment/pos/0907_joint_proj_2b_vf_xgen_context/internvl-pos-33000
  global_step: 33000

  exp_name: &exp_name pos
  wandb_proj: *exp_name
  output_dir: 0908_joint_proj_2b_vf_xgen_context_query
  logging_dir: logs
  mixed_precision: bf16
  gradient_accumulation_steps: 1
  report_to: wandb

  lr: 1e-4
  num_iter: 500000
  save_every: 2000
# --------------------------------------------------
data:
  wds_path: [/data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Long-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-Short-Caption, /data/phd/jinjiachun/dataset/BLIP3o/BLIP3o-Pretrain-JourneyDB]
  use_template: true
  num_train_examples: 35000000
  img_size: 448
  buffer_size: 50000
  batch_size: 20
  num_workers: 8
  cfg_drop_rate: 0.1
  num_img_token: 256
  max_seq_length: 512