machine: "ks" # [g3, ks]

vae_aligner:
  # pretrained_path: "/data/phd/jinjiachun/experiment/vae_aligner/0714_sd3_vae_aligner_hybrid/vae_aligner-vae_aligner-51k"
  pretrained_path: "/data/phd/jinjiachun/experiment/vae_aligner/0714_sd3_vae_aligner_hybrid/vae_aligner-vae_aligner-215k"
  hidden_size: 1024
  depth: 16
  num_heads: 16
  grid_size: 24

  siglip_feature_dim: 1024
  siglip_feature_dim_down: 16

train:
  root:
  resume_path: "/data/phd/jinjiachun/experiment/mmdit/0714_mmdit_dev/transformer-mmdit-30000"
  skipped_keys:
  global_step:

  exp_name: &exp_name "mmdit"
  wandb_proj: *exp_name
  output_dir: "0722_mmdit_215k_aligner"
  logging_dir: "logs"
  mixed_precision: "bf16"
  gradient_accumulation_steps: 1
  report_to: "wandb"

  cfg_drop_rate: 0.1
  add_noise_to_context: false
  context_noise_std: 0.0

  lr: 1e-4
  num_iter: 50000
  save_every: 10000
  val_every: 1000


data:
  name: "t2i"
  train_path:
  batch_size: 40
  num_workers: 8
  img_size: 384
  streaming: true
  buffer_size: 80000
  max_text_length: 192